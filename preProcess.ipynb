{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词典合并去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rm_dupli(path):\n",
    "    with open(path, 'r') as fp1:\n",
    "        word_list = fp1.readlines()\n",
    "        word_rmdu = set([word.strip() for word in word_list])\n",
    "    save_path = path + '_rmdu'\n",
    "    with open(save_path, 'w') as fp2:\n",
    "        fp2.write('\\n'.join(word_rmdu))\n",
    "    print 'The num of', path[14:], 'is', len(word_rmdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The num of sen_neg_dict is 13752\n",
      "The num of sen_pos_dict is 10219\n",
      "The num of sen_neg_pos_dict is 23633\n"
     ]
    }
   ],
   "source": [
    "neg_path = 'data/sen_dict/sen_neg_dict'\n",
    "pos_path = 'data/sen_dict/sen_pos_dict'\n",
    "neg_pos_path = 'data/sen_dict/sen_neg_pos_dict'\n",
    "rm_dupli(neg_path)\n",
    "rm_dupli(pos_path)\n",
    "rm_dupli(neg_pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成停用词表\n",
    "with open('data/sen_dict/sen_neg_pos_dict', 'r') as fp:\n",
    "    word_list = fp.readlines()\n",
    "    sen_words = set([word.strip().decode('utf-8') for word in word_list])\n",
    "with open('data/stop_words_ch.txt', 'r') as fp:\n",
    "    word_list = fp.readlines()\n",
    "    stop_words = [word.strip().decode('gbk') for word in word_list]\n",
    "new_stop_words = [w.encode('utf-8') for w in stop_words if w not in sen_words]\n",
    "with open('data/new_stop_words_ch.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(new_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba.posseg\n",
    "from tqdm import tqdm\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'minors': 11, u'graph': 10, u'system': 6, u'trees': 9, u'eps': 8, u'computer': 1, u'survey': 5, u'user': 7, u'human': 2, u'time': 4, u'interface': 0, u'response': 3}\n",
      "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 3, 7: 3, 8: 2, 9: 3, 10: 3, 11: 2}\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "processed_corpus = [['human', 'interface', 'computer'],\n",
    " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    " ['eps', 'user', 'interface', 'system'],\n",
    " ['system', 'human', 'system', 'eps'],\n",
    " ['user', 'response', 'time'],\n",
    " ['trees'],\n",
    " ['graph', 'trees'],\n",
    " ['graph', 'minors', 'trees'],\n",
    " ['graph', 'minors', 'survey']]\n",
    "# 创建词-词频字典\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "# 查看词典\n",
    "print dictionary.token2id\n",
    "# 查看词在文档集中出现的文档数\n",
    "print dictionary.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分词、去除停用词、去重、词性过滤\n",
    "def sent2word(sentence):\n",
    "    segList = set(jieba.posseg.cut(sentence))\n",
    "    newSent = [w.word for w in segList if w.word not in stop_words and w.flag in pos]\n",
    "    return newSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_path = 'data/ChnSentiCorp_htl_unba_10000/neg'\n",
    "pos_path = 'data/ChnSentiCorp_htl_unba_10000/pos'\n",
    "# 停用词表\n",
    "with open('data/new_stop_words_ch.txt', 'r') as fp:\n",
    "    word_list = fp.readlines()\n",
    "    stop_words = set([word.strip() for word in word_list])\n",
    "# 词性过滤表\n",
    "pos = 'v vd vn vshi vyou vf vx vi vl vg a ad an ag al d'.split()\n",
    "def corpus2list(path):\n",
    "    corpus = []\n",
    "    for parent, _, fileNames in os.walk(path):\n",
    "        for fileName in tqdm(fileNames):\n",
    "            currentPath = os.path.join(parent, fileName)\n",
    "            with open(currentPath, 'r') as fp:\n",
    "                text = fp.read().decode('gbk', 'ignore').strip()\n",
    "                corpus.append(sent2word(text))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [01:14<00:00, 40.30it/s]\n",
      "100%|██████████| 7000/7000 [01:53<00:00, 61.79it/s] \n"
     ]
    }
   ],
   "source": [
    "neg_corpus = corpus2list(neg_path)\n",
    "pos_corpus = corpus2list(pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_corpus_dict = corpora.Dictionary(neg_corpus)\n",
    "pos_corpus_dict = corpora.Dictionary(pos_corpus)\n",
    "del neg_corpus\n",
    "del pos_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算CHI\n",
    "n = 10000.0\n",
    "neg_num = 3000.0\n",
    "pos_num = 7000.0\n",
    "dfs_neg = neg_corpus_dict.dfs  # 词id在文档集中出现的文档数\n",
    "dfs_pos = pos_corpus_dict.dfs\n",
    "neg_chi = {}\n",
    "pos_chi = {}\n",
    "for i, word in neg_corpus_dict.items():\n",
    "    a = dfs_neg[i]\n",
    "    try:\n",
    "        b = dfs_pos[pos_corpus_dict.token2id[word]]\n",
    "    except:\n",
    "        b = 0\n",
    "    c = neg_num - a\n",
    "    d = pos_num - b\n",
    "    x = n*(a*d-b*c)*(a*d-b*c)/neg_num/pos_num/(a+b)/(c+d)  # 计算卡方检验\n",
    "    neg_chi[word] = x\n",
    "\n",
    "for i, word in pos_corpus_dict.items():\n",
    "    a = dfs_pos[i]\n",
    "    try:\n",
    "        b = dfs_neg[neg_corpus_dict.token2id[word]]\n",
    "    except:\n",
    "        b = 0\n",
    "    c = pos_num - a\n",
    "    d = neg_num - b\n",
    "    x = n*(a*d-b*c)*(a*d-b*c)/neg_num/pos_num/(a+b)/(c+d)  # 计算卡方检验\n",
    "    pos_chi[word] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_neg_chi = sorted(neg_chi.items(), key=lambda i:i[1], reverse=True)\n",
    "sort_pos_chi = sorted(pos_chi.items(), key=lambda i:i[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预定 已经 甚至 喜欢 洗 周到 折腾 完全 不敢 睡觉 低 入住 开门 值得 从来 直到 打扫 可怜 敢 退\n",
      "已经 甚至 喜欢 洗 周到 折腾 完全 不敢 睡觉 低 入住 开门 值得 从来 直到 打扫 可怜 敢 退 见\n"
     ]
    }
   ],
   "source": [
    "print ' '.join([i[0] for i in sort_neg_chi[100:120]])\n",
    "print ' '.join([i[0] for i in sort_pos_chi[100:120]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\u51e1', 7.002100630189057),\n",
       " (u'\\u722c\\u51fa', 7.002100630189057),\n",
       " (u'\\u505a\\u7231', 7.002100630189057),\n",
       " (u'\\u6d53\\u539a', 7.002100630189057),\n",
       " (u'\\u76ee\\u7779', 7.002100630189057),\n",
       " (u'\\u8e66\\u8fea', 7.002100630189057),\n",
       " (u'\\u771f\\u76f8', 7.002100630189057),\n",
       " (u'\\u6781\\u70ed', 7.002100630189057),\n",
       " (u'\\u79df\\u7ed9', 7.002100630189057),\n",
       " (u'\\u6ca1\\u64e6', 7.002100630189057)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_neg_chi[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\u53cd\\u8fc7\\u6765', 5.7250960025759525),\n",
       " (u'\\u8bf7\\u793a', 5.7250960025759525),\n",
       " (u'\\u6a21\\u7cca', 5.7250960025759525),\n",
       " (u'\\u61c2\\u5f97', 5.7250960025759525),\n",
       " (u'\\u5f97\\u4e0d\\u5230', 5.7250960025759525),\n",
       " (u'\\u4e8f', 5.7250960025759525),\n",
       " (u'\\u4e0d\\u4fe1', 5.7250960025759525),\n",
       " (u'\\u8bd5\\u95ee', 5.7250960025759525),\n",
       " (u'\\u4e92\\u76f8', 5.7250960025759525),\n",
       " (u'\\u7ad9', 5.663932569804846)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_pos_chi[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
